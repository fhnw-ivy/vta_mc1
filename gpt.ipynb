{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784), (60000,), (10000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define transformations to be applied to the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_set = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_set = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Extract the data and labels from the datasets\n",
    "X_train, y_train = train_set.data.numpy(), train_set.targets.numpy()\n",
    "X_test, y_test = test_set.data.numpy(), test_set.targets.numpy()\n",
    "\n",
    "# Reshape the data to be of size [N x 784]\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Normalize the data to be between 0 and 1\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = np.unique(y_train)\n",
    "\n",
    "# Plot the images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(X_train[y_train == classes[i]][0].reshape(28, 28), cmap='gray')\n",
    "    ax.set_title(f\"Class: {classes[i]}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples:  60000\n",
      "Number of testing examples:  10000\n",
      "Each image is of size:  784\n",
      "There are 10 classes: [0 1 2 3 4 5 6 7 8 9]\n",
      "The data is of type:  float64\n",
      "The labels are of type:  int64\n",
      "The range of the pixel values is [0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print('Number of training examples: ', X_train.shape[0])\n",
    "print('Number of testing examples: ', X_test.shape[0])\n",
    "print('Each image is of size: ', X_train.shape[1])\n",
    "print('There are {} classes: {}'.format(len(classes), classes))\n",
    "print('The data is of type: ', X_train.dtype)\n",
    "print('The labels are of type: ', y_train.dtype)\n",
    "print('The range of the pixel values is [{}, {}]'.format(np.min(X_train), np.max(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer():\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.weights = np.random.randn(input_size, output_size) * 0.01\n",
    "        self.bias = np.zeros((1, output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return np.dot(x, self.weights) + self.bias\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        self.weights_grad = np.dot(self.x.T, grad_output)\n",
    "        self.bias_grad = np.sum(grad_output, axis=0, keepdims=True)\n",
    "        return np.dot(grad_output, self.weights.T)\n",
    "\n",
    "    def update(self, lr):\n",
    "        self.weights -= lr * self.weights_grad\n",
    "        self.bias -= lr * self.bias_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_backward (__main__.TestLinearLayer.test_backward) ... ok\n",
      "test_forward (__main__.TestLinearLayer.test_forward) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x28dae2d90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestLinearLayer(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.input_size = 10\n",
    "        self.output_size = 5\n",
    "        self.linear_layer = LinearLayer(self.input_size, self.output_size)\n",
    "\n",
    "    def test_forward(self):\n",
    "        x = np.random.randn(1, self.input_size)\n",
    "        output = self.linear_layer.forward(x)\n",
    "        self.assertEqual(output.shape, (1, self.output_size))\n",
    "\n",
    "    def test_backward(self):\n",
    "        x = np.random.randn(1, self.input_size)\n",
    "        output = self.linear_layer.forward(x)\n",
    "        grad_output = np.random.randn(1, self.output_size)\n",
    "        grad_input = self.linear_layer.backward(grad_output)\n",
    "        self.assertEqual(grad_input.shape, (1, self.input_size))\n",
    "\n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_grad(x):\n",
    "    return x > 0\n",
    "\n",
    "def sigmoid(x):\n",
    "    x = np.clip(x, -500, 500) # clip x to prevent overflow\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_grad(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def binary_cross_entropy(y_pred, y_true):\n",
    "    eps = 1e-15\n",
    "    y_pred = np.clip(y_pred, eps, 1-eps) # clip y_pred to prevent log(0) or log(1)\n",
    "    loss = -(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred)).mean()\n",
    "    return loss\n",
    "\n",
    "def binary_cross_entropy_grad(y_pred, y_true):\n",
    "    eps = 1e-15\n",
    "    y_pred = np.clip(y_pred, eps, 1-eps) # clip y_pred to prevent division by 0\n",
    "    grad = (y_pred - y_true) / (y_pred * (1 - y_pred) + eps) # add eps to prevent division by 0\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleLayerNetwork():\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.linear1 = LinearLayer(input_size, hidden_size)\n",
    "        self.linear2 = LinearLayer(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.h = relu(self.linear1.forward(x))\n",
    "        self.y_pred = sigmoid(self.linear2.forward(self.h))\n",
    "        return self.y_pred\n",
    "\n",
    "    def backward(self, y_true):\n",
    "        # reshape y_pred to be the same shape as y_true\n",
    "        y_true = y_true.reshape(-1, 1)\n",
    "        self.y_pred = self.y_pred.reshape(-1, 1)\n",
    "\n",
    "        grad_output = binary_cross_entropy_grad(self.y_pred, y_true)\n",
    "        grad_output = sigmoid_grad(self.y_pred) * grad_output\n",
    "        grad_output = self.linear2.backward(grad_output)\n",
    "        grad_output = relu_grad(self.h) * grad_output\n",
    "        grad_output = self.linear1.backward(grad_output)\n",
    "        return grad_output\n",
    "\n",
    "    def update(self, lr):\n",
    "        self.linear1.update(lr)\n",
    "        self.linear2.update(lr)\n",
    "\n",
    "    def train(self, X, y, lr, epochs, batch_size):\n",
    "        for epoch in range(epochs):\n",
    "            loss_list = []\n",
    "            for i in range(0, len(X), batch_size):\n",
    "                # create random batch with batch_size\n",
    "                batch = np.random.choice(len(X), batch_size)\n",
    "                X_batch = X[batch]\n",
    "                y_batch = y[batch]\n",
    "                \n",
    "                # Forward pass\n",
    "                y_pred = self.forward(X_batch)\n",
    "\n",
    "                # Backward pass\n",
    "                loss = binary_cross_entropy(y_pred, y_batch)\n",
    "                loss_list.append(loss)\n",
    "                self.backward(y_batch)\n",
    "                self.update(lr)\n",
    "\n",
    "            accuracy = self.evaluate(X, y)\n",
    "            loss = np.mean(loss_list)\n",
    "            print(f\"Epoch {epoch+1} - Loss: {loss:.4f} - Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = self.forward(X)\n",
    "        return np.argmax(y_pred, axis=1)\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        y_pred = np.round(y_pred)\n",
    "        return np.mean(y_pred == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 6.6283 - Accuracy: 0.9026\n",
      "Epoch 2 - Loss: 6.9815 - Accuracy: 0.9026\n",
      "Epoch 3 - Loss: 6.6070 - Accuracy: 0.9026\n",
      "Epoch 4 - Loss: 6.6791 - Accuracy: 0.9026\n",
      "Epoch 5 - Loss: 6.5441 - Accuracy: 0.9026\n",
      "Epoch 6 - Loss: 6.9283 - Accuracy: 0.9026\n",
      "Epoch 7 - Loss: 6.6448 - Accuracy: 0.9026\n",
      "Epoch 8 - Loss: 6.6791 - Accuracy: 0.9026\n",
      "Epoch 9 - Loss: 6.6796 - Accuracy: 0.9026\n",
      "Epoch 10 - Loss: 6.9226 - Accuracy: 0.9026\n"
     ]
    }
   ],
   "source": [
    "y_train_4 = (y_train == 4).astype(int)\n",
    "y_test_4 = (y_test == 4).astype(int)\n",
    "\n",
    "#Â Train the network\n",
    "network = SingleLayerNetwork(input_size=784, hidden_size=128, output_size=1)\n",
    "network.train(X_train, y_train_4, lr=0.1, epochs=10, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y_pred, y_true):\n",
    "    eps = 1e-15\n",
    "    y_pred = np.clip(y_pred, eps, 1-eps) # clip y_pred to prevent log(0) or log(1)\n",
    "    loss = -(y_true * np.log(y_pred)).sum(axis=1).mean()\n",
    "    return loss\n",
    "\n",
    "def cross_entropy_grad(y_pred, y_true):\n",
    "    eps = 1e-15\n",
    "    y_pred = np.clip(y_pred, eps, 1-eps) # clip y_pred to prevent division by 0\n",
    "    grad = y_pred - y_true\n",
    "    return grad\n",
    "\n",
    "def mse(y_pred, y_true):\n",
    "    loss = ((y_pred - y_true) ** 2).mean()\n",
    "    return loss\n",
    "\n",
    "def mse_grad(y_pred, y_true):\n",
    "    grad = 2 * (y_pred - y_true) / y_pred.size\n",
    "    return grad\n",
    "\n",
    "def softmax(x):\n",
    "    x = x - np.max(x, axis=1, keepdims=True) # prevent overflow\n",
    "    x = np.exp(x)\n",
    "    x = x / np.sum(x, axis=1, keepdims=True)\n",
    "    return x\n",
    "\n",
    "def softmax_grad(x):\n",
    "    return softmax(x) * (1 - softmax(x))\n",
    "\n",
    "def one_hot_encode(y):\n",
    "    y_one_hot = np.zeros((len(y), 10))\n",
    "    y_one_hot[np.arange(len(y)), y] = 1\n",
    "    return y_one_hot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient of the Cross-Entropy loss function\n",
    "The reason why the `cross_entropy_grad` function uses the difference between the predicted probabilities and the true labels, instead of the negative of the gradient of the cross-entropy loss with respect to the predicted probabilities, is that they are equivalent up to a constant factor.\n",
    "\n",
    "Let's first consider the gradient of the cross-entropy loss with respect to the predicted logits, denoted as $\\mathbf{z}$. The logits are related to the predicted probabilities via the softmax function:\n",
    "\n",
    "$$\n",
    "y_{i} = \\frac{e^{z_{i}}}{\\sum_{j} e^{z_{j}}}\n",
    "$$\n",
    "\n",
    "Taking the partial derivative of $\\mathcal{L}$ with respect to $z_{j}$, we have:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial z_{j}} = \\sum_{i} \\frac{\\partial \\mathcal{L}}{\\partial y_{i}} \\frac{\\partial y_{i}}{\\partial z_{j}}\n",
    "$$\n",
    "\n",
    "Using the chain rule, we have:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial y_{i}}{\\partial z_{j}} = y_{i} (\\delta_{ij} - y_{j})\n",
    "$$\n",
    "\n",
    "where $\\delta_{ij}$ is the Kronecker delta function that is equal to 1 if $i = j$ and 0 otherwise. Substituting this expression into the above equation, we obtain:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial z_{j}} = \\sum_{i} (\\delta_{ij} - y_{j}) t_{i}\n",
    "$$\n",
    "\n",
    "This expression is equivalent to the difference between the predicted probabilities and the true labels. To see this, note that the predicted probabilities can be written as:\n",
    "\n",
    "$$\n",
    "y_{j} = \\frac{e^{z_{j}}}{\\sum_{k} e^{z_{k}}}\n",
    "$$\n",
    "\n",
    "Taking the derivative of $y_{j}$ with respect to $z_{j}$, we have:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial y_{j}}{\\partial z_{j}} = y_{j} (1 - y_{j})\n",
    "$$\n",
    "\n",
    "Substituting this expression into the gradient expression, we obtain:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial z_{j}} = y_{j} - t_{j}\n",
    "$$\n",
    "\n",
    "which is the difference between the predicted probabilities and the true labels. Thus, the `cross_entropy_grad` function is equivalent to the negative of the gradient of the cross-entropy loss with respect to the predicted probabilities, up to a constant factor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerNetwork():\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.linear1 = LinearLayer(input_size, hidden_size)\n",
    "        self.linear2 = LinearLayer(hidden_size, hidden_size)\n",
    "        self.linear3 = LinearLayer(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.h1 = relu(self.linear1.forward(x))\n",
    "        self.h2 = relu(self.linear2.forward(self.h1))\n",
    "        self.y_pred = softmax(self.linear3.forward(self.h2))\n",
    "        return self.y_pred\n",
    "\n",
    "    def backward(self, y_true):\n",
    "        grad_output = cross_entropy_grad(self.y_pred, y_true)\n",
    "        grad_output = softmax_grad(self.y_pred) * grad_output\n",
    "        grad_output = self.linear3.backward(grad_output)\n",
    "        grad_output = relu_grad(self.h2) * grad_output\n",
    "        grad_output = self.linear2.backward(grad_output)\n",
    "        grad_output = relu_grad(self.h1) * grad_output\n",
    "        grad_output = self.linear1.backward(grad_output)\n",
    "        return grad_output\n",
    "\n",
    "    def update(self, lr):\n",
    "        self.linear1.update(lr)\n",
    "        self.linear2.update(lr)\n",
    "        self.linear3.update(lr)\n",
    "\n",
    "    def train(self, X, y, lr, epochs, batch_size):\n",
    "        for epoch in range(epochs):\n",
    "            loss_list = []\n",
    "            for i in range(0, len(X), batch_size):\n",
    "                # create random batch with batch_size\n",
    "                batch = np.random.choice(len(X), batch_size)\n",
    "                X_batch = X[batch]\n",
    "                y_batch = y[batch]\n",
    "                \n",
    "                # Forward pass\n",
    "                y_pred = self.forward(X_batch)\n",
    "\n",
    "                # Backward pass\n",
    "                loss = cross_entropy(y_pred, y_batch)\n",
    "                loss_list.append(loss)\n",
    "                self.backward(y_batch)\n",
    "                self.update(lr)\n",
    "\n",
    "            accuracy = self.evaluate(X, y)\n",
    "            loss = np.mean(loss_list)\n",
    "            print(f\"Epoch {epoch+1} - Loss: {loss:.4f} - Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = self.forward(X)\n",
    "        return np.argmax(y_pred, axis=1)\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        return np.mean(y_pred == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39m# one hot encode the labels\u001b[39;00m\n\u001b[1;32m      5\u001b[0m y_train_one_hot \u001b[39m=\u001b[39m one_hot_encode(y_train)\n\u001b[0;32m----> 6\u001b[0m network\u001b[39m.\u001b[39;49mtrain(X_train, y_train_one_hot, lr\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m46\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[11], line 42\u001b[0m, in \u001b[0;36mMultiLayerNetwork.train\u001b[0;34m(self, X, y, lr, epochs, batch_size)\u001b[0m\n\u001b[1;32m     39\u001b[0m y_batch \u001b[39m=\u001b[39m y[batch]\n\u001b[1;32m     41\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(X_batch)\n\u001b[1;32m     44\u001b[0m \u001b[39m# Backward pass\u001b[39;00m\n\u001b[1;32m     45\u001b[0m loss \u001b[39m=\u001b[39m cross_entropy(y_pred, y_batch)\n",
      "Cell \u001b[0;32mIn[11], line 12\u001b[0m, in \u001b[0;36mMultiLayerNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     11\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m x\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mh1 \u001b[39m=\u001b[39m relu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear1\u001b[39m.\u001b[39;49mforward(x))\n\u001b[1;32m     13\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mh2 \u001b[39m=\u001b[39m relu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear2\u001b[39m.\u001b[39mforward(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mh1))\n\u001b[1;32m     14\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_pred \u001b[39m=\u001b[39m softmax(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear3\u001b[39m.\u001b[39mforward(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mh2))\n",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m, in \u001b[0;36mLinearLayer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m      9\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m x\n\u001b[0;32m---> 10\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mdot(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "network = MultiLayerNetwork(input_size=784, hidden_size=256, output_size=10)\n",
    "\n",
    "# one hot encode the labels\n",
    "y_train_one_hot = one_hot_encode(y_train)\n",
    "network.train(X_train, y_train_one_hot, lr=0.01, epochs=10, batch_size=46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the network on the test set\n",
    "print(f\"Accuracy: {network.evaluate(X_test, one_hot_encode(y_test)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 10 random images from the test set with their predicted labels\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    idx = np.random.choice(len(X_test))\n",
    "    ax.imshow(X_test[idx].reshape(28, 28), cmap=\"gray\")\n",
    "    ax.set_title(f\"Prediction: {network.predict(X_test[idx:idx+1])[0]}\")\n",
    "    ax.axis(\"off\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
